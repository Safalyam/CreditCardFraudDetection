{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJmMaZYPiArF"
   },
   "source": [
    "## Credit Card Fraud Detection\n",
    "#### Submitted by: Safalya Mohanta\n",
    "\n",
    "**Objective:** Predict fraudulent credit card transactions with the help of Machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1-Ly0yOziArQ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the required libraries here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import linear_model #import the package\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNqlW4CfiEaJ",
    "outputId": "79361bd8-b6aa-43a9-f987-133b1360f3cd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12832\\1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX6BRQwaiArU"
   },
   "source": [
    "## Exploratory data analysis -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "tXiBF-6iiArV",
    "outputId": "90f1fc17-56b7-4dbd-e1f1-076c7a7b998d"
   },
   "outputs": [],
   "source": [
    "# Load the given data\n",
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTghToIDiArX",
    "outputId": "c51a80b1-41dd-44ba-feb5-962085209582"
   },
   "outputs": [],
   "source": [
    "#observe the different feature type present in the data\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P3jDcXtxiArY",
    "outputId": "a7520dc1-1780-4aeb-8d4f-88192db292fc"
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qxb5H-H1iAra",
    "outputId": "62922d1c-f208-46e3-cd66-b921ac8a37af"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYOh9jcfiArb"
   },
   "source": [
    "**Insight:**\n",
    "* Data has no records will null values\n",
    "* Data is already PCA transformed\n",
    "* Data has **284,807 rows** and **31 columns**\n",
    "* Datatype of the 'Class' variable is 'int'. Class vaiable should be categorical (0: non fraud & 1:fraud), we need to change  datatype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Smq_M7viArc",
    "outputId": "94551e7b-ca48-4a22-b9a3-cd4332435adc"
   },
   "outputs": [],
   "source": [
    "#Changing the data type of Class\n",
    "\n",
    "df['Class'] = df['Class'].astype('category')\n",
    "\n",
    "#Renaming the classes\n",
    "df['Class'] = df['Class'].cat.rename_categories({1:'Fraudulent',0:'Non_Fraudulent'})\n",
    "\n",
    "df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIm1rAmWiAre"
   },
   "source": [
    "* Here we will observe the distribution of our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PP9_gYbGiArf",
    "outputId": "257358e3-54ca-48db-d620-5a0a046ee18b"
   },
   "outputs": [],
   "source": [
    "classes=df['Class'].value_counts()\n",
    "normal_share=classes[0]/df['Class'].count()*100\n",
    "fraud_share=classes[1]/df['Class'].count()*100\n",
    "print(normal_share)\n",
    "print(fraud_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "ATX_EYrtiArg",
    "outputId": "6704848d-8e9a-4cca-85af-2dac2d911cea"
   },
   "outputs": [],
   "source": [
    "#Creating a df for percentage of each class\n",
    "class_share = {'Class':['1','0'],'Percentage':[fraud_share,normal_share]}\n",
    "class_share = pd.DataFrame(class_share)\n",
    "class_share.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR_gg2cMiArg"
   },
   "source": [
    "* Data is **imbalanced**. Only **0.17%** data represents **fradulent** cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "GAZ8vChgiArh",
    "outputId": "caa776b3-616b-4d00-d260-36ee822d8007"
   },
   "outputs": [],
   "source": [
    "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "plt.figure(figsize=(13,7))\n",
    "plt.subplot(121)\n",
    "plt.title('Fraudulent BarPlot', fontweight='bold',fontsize=14)\n",
    "ax = df['Class'].value_counts().plot(kind='bar')\n",
    "total = float(len(df))\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.5f}'.format(height/total),\n",
    "            ha=\"center\") \n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "df[\"Class\"].value_counts().plot.pie(autopct = \"%1.5f%%\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "bYLa9odniAri",
    "outputId": "8e920ee2-b480-401b-bc47-46ea9d5bfe74"
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with time\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.stripplot(x= 'Class', y= 'Time',data=df)\n",
    "plt.title('Distribution of Classes with Time\\n (0: Non-Fraudulent || 1: Fraudulent)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIOo6pQSiArj"
   },
   "source": [
    "**Insight**\n",
    "* There isn't any particular time interval at which fraudulent transactions happen. It can happen at any time.\n",
    "* The Time column is evenly distributed for fraudulent transactions and doesn't seem to have any role in deciding whether a transaction is fraud or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "olKL0O5HiArk",
    "outputId": "292c6fd6-6a17-49bb-e115-914dce8a6569"
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with Amount\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.stripplot(x= 'Class', y= 'Amount',data=df)\n",
    "plt.title('Distribution of Classes with Amount\\n (0: Non-Fraudulent || 1: Fraudulent)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uiV8wDgiArl"
   },
   "source": [
    "**Insight:**\n",
    "* Fraudulent transactions do not have any high amount transactions. The maximum amount for a fraudulent transaction is  around $2500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnIYwOFjiArl",
    "outputId": "421c8662-5c13-4000-eb0e-caf0e7aff4d2"
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "# Dropping the column 'Time' since it does not have any impact on deciding a fraud transaction\n",
    "df=df.drop('Time',axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "VCPFNCbviArm",
    "outputId": "2dd1e479-ed80-4600-d20c-eb5faf358512"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "sns.heatmap(df.corr(),linewidths=0.5,cmap='YlGnBu')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3_-6B7iiArn"
   },
   "source": [
    "* This is a PCA converted data, there isn't much to conclude from the heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoGsYt_LiArn"
   },
   "source": [
    "### Splitting the data into train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "PRnE9eT8iArn",
    "outputId": "b6b6d4af-606e-443e-ada1-ca6e23595db3"
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"Class\"], axis = 1)\n",
    "y= df['Class']\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmS_N6PEiAro"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)\n",
    "#Using stratify=y so that proportion of each class is same in both train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8JxOzdUiAro"
   },
   "source": [
    "##### Preserve X_test & y_test to evaluate on the test data once you build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YY7NIuSziArp"
   },
   "outputs": [],
   "source": [
    "#print(np.sum(y))\n",
    "#print(np.sum(y_train))\n",
    "#print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6R4xxE5iArp",
    "outputId": "c633292a-c22e-4027-93cd-895216822f7e"
   },
   "outputs": [],
   "source": [
    "print('Total count for each class:\\n', y.value_counts())\n",
    "print(\"\\nCount of each class in train data:\\n\",y_train.value_counts())\n",
    "print(\"\\nCount of each class in test data:\\n\",y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEzDpdnViArp"
   },
   "source": [
    "### Plotting the distribution of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wfEOfpMSiArq",
    "outputId": "4429f2ca-f7a3-42de-cb6c-fea5bdbcd52f"
   },
   "outputs": [],
   "source": [
    "# plot the histogram of a variable from the dataset to see the skewness\n",
    "# ploting distribution plot for all columns to check the skewness\n",
    "\n",
    "#Loop for creating histplot.\n",
    "\n",
    "collist = list(X_train.columns)\n",
    "\n",
    "c = len(collist)\n",
    "m = 1\n",
    "n = 0\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "\n",
    "for i in collist:\n",
    "  if m in range(1,c+1):\n",
    "    plt.subplot(8,4,m)\n",
    "    sns.histplot(X_train[X_train.columns[n]])\n",
    "    m=m+1\n",
    "    n=n+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0blboW9liArq"
   },
   "source": [
    "**Insight:**\n",
    "\n",
    "* Plotted distribution plots for all the variables and it is clearly that there are some variables which are skewed either towards left or right.\n",
    "* This implies all variables are not normally distributed as expected even if this is a PCA transformed dataset.\n",
    "* Transform the data to remove the skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnM5z9YNiArq"
   },
   "source": [
    "### If there is skewness present in the distribution use:\n",
    "- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1bDQ1LHiArr"
   },
   "outputs": [],
   "source": [
    "# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\n",
    "X_train = power_transform(X_train,method='yeo-johnson')\n",
    "X_test = power_transform(X_test,method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svXjehgliArr"
   },
   "outputs": [],
   "source": [
    "# Converting X_train & X_test back to dataframe\n",
    "cols = X.columns\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = cols\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KYBtSDZViArr",
    "outputId": "5e26cc45-3d5e-40f0-bafd-fbb030aec772"
   },
   "outputs": [],
   "source": [
    "# plot the histogram of a variable from the dataset again to see the result \n",
    "# Plotting same set of variables as earlier to identify the difference.\n",
    "\n",
    "#Loop for creating histplot.\n",
    "\n",
    "collist = list(X_train.columns)\n",
    "\n",
    "c = len(collist)\n",
    "m = 1\n",
    "n = 0\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "\n",
    "for i in collist:\n",
    "  if m in range(1,c+1):\n",
    "    plt.subplot(8,4,m)\n",
    "    sns.histplot(X_train[X_train.columns[n]])\n",
    "    m=m+1\n",
    "    n=n+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8ZWKmHiiArr"
   },
   "source": [
    "**Insight:**\n",
    "* After the Power transformation the variables are more gaussian like.\n",
    "* Changes in V1, V12, V26 and Amount coulmn are quite evident. \n",
    "* Skewness has been removed to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzxssG-3iArs"
   },
   "source": [
    "## Model Building\n",
    "- Build different models on the imbalanced dataset and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6P6oLf--iArs"
   },
   "outputs": [],
   "source": [
    "# Function to plot ROC curve and classification score which will be used for each model\n",
    "def plot_roc(fpr,tpr):\n",
    "    plt.plot(fpr, tpr, color='green', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='yellow', linestyle='--')\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def clf_score(clf):\n",
    "    prob = clf.predict_proba(X_test)\n",
    "    prob = prob[:, 1]\n",
    "    auc = roc_auc_score(y_test, prob)    \n",
    "    print('AUC: %.2f' % auc)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,prob, pos_label='Non_Fraudulent')\n",
    "    plot_roc(fpr,tpr)\n",
    "    predicted=clf.predict(X_test)\n",
    "    report = classification_report(y_test, predicted)\n",
    "    print(report)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB6sqUhjiArs"
   },
   "source": [
    "#### Logistic Regresson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sh4u12LtiArt",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "num_C = [0.001,0.01,0.1,1,10,100] #--> list of values\n",
    "#cv_num =   #--> list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PuyDU59iArt",
    "outputId": "1d118794-4e22-4c40-cafb-6c1ff2910c2f"
   },
   "outputs": [],
   "source": [
    "for cv_num in num_C:\n",
    "  clf = LogisticRegression(penalty='l2',C=cv_num,random_state = 0)\n",
    "  clf.fit(X_train, y_train)\n",
    "  print('C:', cv_num)\n",
    "  print('Coefficient of each feature:', clf.coef_)\n",
    "  print('Training accuracy:', clf.score(X_train, y_train))\n",
    "  print('Test accuracy:', clf.score(X_test, y_test))\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRBSKt41iArt"
   },
   "source": [
    "* The best C value is the one for which the difference between train and test score is the least.\n",
    "* In our case the best value of **C=0.01**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyIEVEMdiArt"
   },
   "source": [
    "#### perfom cross validation on the X_train & y_train to create:\n",
    "- X_train_cv\n",
    "- X_test_cv \n",
    "- y_train_cv\n",
    "- y_test_cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQqgJEgCiAru",
    "outputId": "46b91422-2538-4387-d078-7d8634aa08c4"
   },
   "outputs": [],
   "source": [
    "#perform cross validation\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}  # l2 ridge\n",
    "\n",
    "lsr = LogisticRegression()\n",
    "clf_lsr_cv = GridSearchCV(lsr,grid,cv=3,scoring='roc_auc')\n",
    "clf_lsr_cv.fit(X_train,y_train)\n",
    "\n",
    "#perform hyperparameter tuning\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_lsr_cv.best_params_)\n",
    "print(\"accuracy :\",clf_lsr_cv.best_score_)\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "\n",
    "#print the optimum value of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "W389rI--iAru",
    "outputId": "324b7fa3-98a1-4c43-9c94-5bec7136640d"
   },
   "outputs": [],
   "source": [
    "# Fitting the model with best parameters .\n",
    "\n",
    "lsr_best = LogisticRegression(penalty='l2',C=0.01,random_state = 0)\n",
    "lsr_clf = lsr_best.fit(X_train,y_train)\n",
    "clf_score(lsr_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzb_TzIKiAru"
   },
   "source": [
    "* Best parameters : {'C': 0.01, 'penalty': 'l2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6uOb_96iArv"
   },
   "source": [
    "### Similarly explore other algorithms by building models like:\n",
    "- KNN\n",
    "- SVM\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvBj19KoiArv"
   },
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gg0eD3OiArv"
   },
   "outputs": [],
   "source": [
    "#K-Nearest Neighbor\n",
    "# Taking only odd integers as K values to apply the majority rule. \n",
    "k_range = np.arange(1, 20, 2)\n",
    "scores = [] #to store cross val score for each k\n",
    "k_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46yDh3tviArv"
   },
   "outputs": [],
   "source": [
    "# Finding the best k with stratified K-fold method. \n",
    "# We will use cv=3 in cross_val_score to specify the number of folds in the (Stratified)KFold.\n",
    "\n",
    "for k in k_range:\n",
    "  knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "  knn_clf.fit(X_train,y_train)\n",
    "  score = cross_val_score(knn_clf, X_train, y_train, cv=3, n_jobs = -1)\n",
    "  scores.append(score.mean())\n",
    "\n",
    "#Storing the mean squared error to decide optimum k\n",
    "mse = [1-x for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RgzeOLFiArv"
   },
   "outputs": [],
   "source": [
    "#Plotting a line plot to decide optimum value of K\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(121)\n",
    "sns.lineplot(k_range,mse,markers=True,dashes=False)\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.subplot(122)\n",
    "sns.lineplot(k_range,scores,markers=True,dashes=False)\n",
    "plt.xlabel(\"Value of K\")\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-asH64_iArw"
   },
   "source": [
    "* From the above plot optimum K value is 3 for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEl1xqKuiArw"
   },
   "outputs": [],
   "source": [
    "#Fitting the best parameter to the model\n",
    "# 3 fold cross validation with K=3\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_clf = knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJCMzFq9iArw"
   },
   "outputs": [],
   "source": [
    "# Checking AUC \n",
    "\n",
    "clf_score(knn_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZZXvG3GiArw"
   },
   "source": [
    "* The KNN model with imbalanced data gives AUC of 0.94 which is pretty good but recall is 0.77 which is the score should be  improved in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJYKiOQWiArx"
   },
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ks-6x77_iArx",
    "outputId": "31f43a4f-8984-49cc-83b6-15087bc87cb0"
   },
   "outputs": [],
   "source": [
    "# 5 fold cross validation for getting best parameter\n",
    "\n",
    "depth_score=[]\n",
    "dep_rng = [x for x in range(1,20)]\n",
    "for i in dep_rng:\n",
    "  clf = tree.DecisionTreeClassifier(max_depth=i)\n",
    "  score_tree = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5, n_jobs=-1)\n",
    "  depth_score.append(score_tree.mean())\n",
    "print(depth_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "L6Cpd5lHiArx",
    "outputId": "c4ea0204-31b9-48fa-adee-0172bedcc714"
   },
   "outputs": [],
   "source": [
    "#Plotting depth against score\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.lineplot(x=dep_rng,y=depth_score,markers=True,dashes=False)\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Cross Validation Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlo9FosviArx"
   },
   "source": [
    "* The score for depth=5 is the highest. We will use this in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "oOlUlDRniAry",
    "outputId": "e47a4aac-36b8-4587-dda7-b7fbd4400a09"
   },
   "outputs": [],
   "source": [
    "#Fitting the model with depth=5 and plotting ROC curve\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "dt_clf = dt.fit(X_train,y_train)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(dt_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m-m2FrtiAry"
   },
   "source": [
    "* The AUC score for decision tree is only 0.88 which is not satisfactory. The precison and recall are also lower than KNN and logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvHfkgDPiAry"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdDSB8i5iAry",
    "outputId": "233f1763-14b7-4dd8-f7ab-0ff3b1dfc7ce"
   },
   "outputs": [],
   "source": [
    "# Using grid search cv to find the best parameters.\n",
    "\n",
    "param = {'n_estimators': [10, 20, 30, 40, 50], 'max_depth': [2, 3, 4, 7, 9]}\n",
    "rfc = RandomForestClassifier()\n",
    "clf_rfc_cv = GridSearchCV(rfc, param, cv=5,scoring='roc_auc', n_jobs=-1)\n",
    "clf_rfc_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_rfc_cv.best_params_)\n",
    "print(\"accuracy :\",clf_rfc_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB_vTI-WiArz"
   },
   "source": [
    "* We will use these parameters for Random forest {'max_depth': 9, 'n_estimators': 50}. The Accuracy is 0.979 which is very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "ZPQflse5iArz",
    "outputId": "b70dc84c-09ce-4400-96b4-1924047b3a61"
   },
   "outputs": [],
   "source": [
    "#Fitting model and plotting ROC\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=9, n_estimators=50)\n",
    "RFC_clf = rf.fit(X_train,y_train)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(RFC_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TMBJY-OiArz"
   },
   "source": [
    "* We are getting very good precision(0.97) for Faudulent class which is very good along with the AUC of 0.97\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4mt8YVCiAr0"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6RAUhfUiAr0"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOfBrQEtiAr0",
    "outputId": "57d70b45-ce30-4b8f-f704-08ef3e4e8c18"
   },
   "outputs": [],
   "source": [
    "# Using grid search cv to find the best parameters.\n",
    "\n",
    "xgbst = XGBClassifier()\n",
    "\n",
    "param_xgb = {'n_estimators': [25],\n",
    "             } \n",
    "\n",
    "clf_xgb_cv = GridSearchCV(xgbst, param_xgb, cv=3,scoring='roc_auc', n_jobs=-1)\n",
    "clf_xgb_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",clf_xgb_cv.best_params_)\n",
    "print(\"accuracy :\",clf_xgb_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aPX-LUjiAr1"
   },
   "source": [
    "* We got the best parameters for XGboost as following.\n",
    "tuned hpyerparameters : {'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 150} AUC : 0.985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "9VnhIcBViAr1",
    "outputId": "0ea97971-667e-4b78-92fc-a8d54514b367"
   },
   "outputs": [],
   "source": [
    "#Fitting the model with best parameters.\n",
    "\n",
    "xgbst = XGBClassifier(n_estimators=25,max_depth=5,min_child_weight=3)\n",
    "\n",
    "xgb_clf = xgbst.fit(X_train,y_train)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3DJlbiiiAr1"
   },
   "source": [
    "* Got AUC of 0.96 with f1-score of 0.82 which is good.\n",
    "* Recall is 0.74 which is better than our other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmDAfS66iAr1"
   },
   "source": [
    "#### Proceed with the model which shows the best result \n",
    "- Apply the best hyperparameter on the model\n",
    "- Predict on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qx4lnvCiAr2"
   },
   "source": [
    "* Out of the 5 models XGBoost performed the best with AUC of 0.98 and Recall of 0.78.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "s1R6poXriAr2",
    "outputId": "e1afe8db-f91f-4b03-fdfc-37ccd7af4f28"
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(n_estimators=25,max_depth=5,min_child_weight=3)  #initialise the model with optimum hyperparameters\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print the evaluation score on the X_test by choosing the best evaluation metric\n",
    "clf_score(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGOP4Qa3iAr2"
   },
   "source": [
    "### Print the important features of the best model to understand the dataset\n",
    "- This will not give much explanation on the already transformed dataset\n",
    "- But it will help us in understanding if the dataset is not PCA transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7vPVAAZiAr2",
    "outputId": "d4e9a40a-da10-4af4-b91b-8f2f62384caa"
   },
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in clf.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
    "\n",
    "# Variable on Index-16 and Index-13 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJzKJS3viAr2"
   },
   "source": [
    "## Model building with balancing Classes\n",
    "\n",
    "##### Perform class balancing with :\n",
    "- Random Oversampling\n",
    "- SMOTE\n",
    "- ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzTS82W48K8I"
   },
   "source": [
    "#### Class balancing with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqhmTay18esT",
    "outputId": "0b33eba5-e5a0-42aa-928d-31cf40180b2b"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_train_ros, y_train_ros = ros.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdIOYlNgiAr3"
   },
   "source": [
    "#### Class balancing with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGygsrAliAr3",
    "outputId": "82805960-fd93-4119-8702-4f193ae0b9a0"
   },
   "outputs": [],
   "source": [
    "#importing SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X_sm, y_sm = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YpsIfrpiAr3",
    "outputId": "b9cea9e6-dd33-45e3-d1ca-e11c6c9e2c37"
   },
   "outputs": [],
   "source": [
    "#CHecking shape and class count after smote\n",
    "from collections import Counter\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_sm))\n",
    "print(X_sm.shape)\n",
    "print(y_sm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIJDp2v5iAr3"
   },
   "source": [
    "* As seen above the count of each class is same after SMOTE resampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnOTeJfxiAr3"
   },
   "source": [
    "#### Class Balancing with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yq6uAzEXiAr4",
    "outputId": "dd3cbcc4-0333-4607-a380-7bf5bd0f0f8a"
   },
   "outputs": [],
   "source": [
    "# importing ADASYN\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "ada = ADASYN()\n",
    "X_ada, y_ada = ada.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTQUXqzciAr4",
    "outputId": "04c6916d-a724-47cc-cc62-216b1b36d4f3"
   },
   "outputs": [],
   "source": [
    "# CHecking shape and class count after ADASYN\n",
    "from collections import Counter\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_ada))\n",
    "print(X_ada.shape)\n",
    "print(y_ada.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3IHuNKAiAr4"
   },
   "source": [
    "## Model Building\n",
    "- Build different models on the balanced dataset and see the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5crXX9SUiAr4"
   },
   "source": [
    "* Use tuned models which was built on imbalanced data, with both SMOTE and ADASYN technique and see which one gives the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf6-Z6bH84FM"
   },
   "source": [
    "#### Logistic Regression with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S4QXDiXT9KDJ",
    "outputId": "b88da052-4f96-4cc2-ab8f-b635196453f9"
   },
   "outputs": [],
   "source": [
    "lsr_best = LogisticRegression(penalty='l2',C=0.01,random_state = 0)\n",
    "lsr_ros = lsr_best.fit(X_train_ros,y_train_ros)\n",
    "\n",
    "# Printing ROC curve and accuracy scores\n",
    "clf_score(lsr_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e95efd4ZiAr4"
   },
   "source": [
    "#### Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "424xh_rDiAr5",
    "outputId": "a9baa761-7428-4454-b21c-4f217e1612c4"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# Using the best parameters that we got from the cross validation on imbalanced data.\n",
    "\n",
    "lsr_best = LogisticRegression(penalty='l2',C=0.01,random_state = 0)\n",
    "lsr_sm = lsr_best.fit(X_sm,y_sm)\n",
    "\n",
    "# Printing ROC curve and accuracy scores\n",
    "clf_score(lsr_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9gy1AI8iAr5"
   },
   "source": [
    "#### Logistic regression with ADASYN¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AGQvVDB7iAr5",
    "outputId": "312b7e76-31e1-4d2d-abfd-43aec28f5edf"
   },
   "outputs": [],
   "source": [
    "lsr_ada = lsr_best.fit(X_ada,y_ada)\n",
    "\n",
    "# Printing ROC curve and accuracy scores\n",
    "clf_score(lsr_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOcFvo1RiAr5"
   },
   "source": [
    "**Insight**\n",
    "* AUC & Recall both are better on SMOTE.\n",
    "* But the f1-score is extremely low. Model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKyQ5zZg9pmB"
   },
   "source": [
    "#### KNN with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H66H57Bl9vLJ"
   },
   "outputs": [],
   "source": [
    "# KNN with ROS re-sampled data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_roc = knn.fit(X_train_ros,y_train_ros)\n",
    "\n",
    "#Printing ROC \n",
    "\n",
    "clf_score(knn_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKDLbCMRiAr6"
   },
   "source": [
    "#### KNN with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBtA9-nYiAr6"
   },
   "outputs": [],
   "source": [
    "# KNN with SMOTE re-sampled data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_sm = knn.fit(X_sm,y_sm)\n",
    "\n",
    "#Printing ROC \n",
    "\n",
    "clf_score(knn_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRH9w5LriAr6"
   },
   "source": [
    "#### KNN on ADASYN¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hy6ZS0jJiAr6"
   },
   "outputs": [],
   "source": [
    "# KNN with ADASYN re-sampled data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_ada = knn.fit(X_ada,y_ada)\n",
    "\n",
    "#Printing ROC \n",
    "\n",
    "clf_score(knn_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xax1W7eniAr7"
   },
   "source": [
    "* KNN gives same recall(0.88) on both SMOTE and ADASYN.\n",
    "* But on SMOTE, the AUC & f1-score are slightly better. So, KNN performs better on SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhu-LvZT-By7"
   },
   "source": [
    "#### Decision Tree with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AY74VYyT-InA",
    "outputId": "8205ff7b-87c8-469a-edf4-15477cb90844"
   },
   "outputs": [],
   "source": [
    "# Building model with ROS\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "dt_ros = dt.fit(X_train_ros,y_train_ros)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(dt_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASOEpSWBiAr7"
   },
   "source": [
    "#### Decision Tree on Smote¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZQP-OR3-iAr8",
    "outputId": "55b9b48f-aa67-454b-fd0e-fc770476c81c"
   },
   "outputs": [],
   "source": [
    "# Building model with SMOTE\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "dt_sm = dt.fit(X_sm,y_sm)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(dt_sm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wybnPqYAiAr8"
   },
   "source": [
    "#### Decision Tree on ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-6yGjD3WiAr8",
    "outputId": "72015faf-e167-4745-a841-daecb0c34639"
   },
   "outputs": [],
   "source": [
    "# Building model with ADASYN\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "dt_ada = dt.fit(X_ada,y_ada)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(dt_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cphi1O9yiAr8"
   },
   "source": [
    "* AUC is higher in SMOTE by a small margin but Recall is better in ADASYN than SMOTE.\n",
    "* The Precision is extremely low in both, resulting in low f1-score. So the model is not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etZozaMF-cfI"
   },
   "source": [
    "#### Random Forest with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ru-FkCwW-hD5",
    "outputId": "a16e565e-0407-4da1-94f5-89136e3b449e"
   },
   "outputs": [],
   "source": [
    "#Building Random forest with best parameters on SMOTE\n",
    "rf = RandomForestClassifier(max_depth=9, n_estimators=30)\n",
    "RFC_ros = rf.fit(X_train_ros,y_train_ros)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(RFC_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbtcJAmciAr8"
   },
   "source": [
    "#### Random Forest on SMOTE¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gkx6TRFmiAr9",
    "outputId": "e99491bc-2199-45d5-dd52-b7c74419fb36"
   },
   "outputs": [],
   "source": [
    "#Building Random forest with best parameters on SMOTE\n",
    "rf = RandomForestClassifier(max_depth=9, n_estimators=30)\n",
    "RFC_sm = rf.fit(X_sm,y_sm)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(RFC_sm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6m2Q1HXdiAr9"
   },
   "source": [
    "#### Random Forest on ADASYN¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YR6WnONniAr9",
    "outputId": "4bcd98d1-b892-435b-d407-dd485037e177"
   },
   "outputs": [],
   "source": [
    "#Building Random forest with best parameters on ADASYN\n",
    "rf = RandomForestClassifier(max_depth=9, n_estimators=30)\n",
    "RFC_ada = rf.fit(X_ada,y_ada)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(RFC_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZvf87RziAr9"
   },
   "source": [
    "**Insight**\n",
    "* Random Forest performs better on SMOTE.\n",
    "* Both AUC and Recall for Fraud transactions are better on ADASYN sampled data, but Precision is extremely low.\n",
    "* Where as in SMOTE we have a fair precision with good recall resulting in a fair f1-score(0.57)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0X3xXNY-1qp"
   },
   "source": [
    "#### XGBoost with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ecc6UrVk-6nI",
    "outputId": "ef0a0f3e-f8db-4a01-afae-6b6c0f27af57"
   },
   "outputs": [],
   "source": [
    "X_ros = pd.DataFrame(X_train_ros)\n",
    "X_ros.columns = cols\n",
    "\n",
    "X_train_ros = pd.DataFrame(X_train_ros)\n",
    "X_train_ros.columns = cols\n",
    "\n",
    "xgbst = XGBClassifier(n_estimators=25,max_depth=5,min_child_weight=3)\n",
    "\n",
    "xgb_ros = xgbst.fit(X_train_ros,y_train_ros)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(xgb_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxXl83TOiAr-"
   },
   "source": [
    "#### XGBoost with SMOTE¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4bknFYbiAr-"
   },
   "outputs": [],
   "source": [
    "# Since X_sm and X_ada are arrays, we need to covert them to dataframes to avoid feature mismatch error \n",
    "X_sm = pd.DataFrame(X_sm)\n",
    "X_sm.columns = cols\n",
    "\n",
    "X_ada = pd.DataFrame(X_ada)\n",
    "X_ada.columns = cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lPRhkrd0iAr-",
    "outputId": "4191199e-2ed5-4170-830d-e57b87f8f945"
   },
   "outputs": [],
   "source": [
    "#Fitting the XGBoost model with best parameters on SMOTE\n",
    "\n",
    "xgbst = XGBClassifier(n_estimators=25,max_depth=5,min_child_weight=3)\n",
    "\n",
    "xgb_sm = xgbst.fit(X_sm,y_sm)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(xgb_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2yqtv2viAr-"
   },
   "source": [
    "#### XGBoost with ADASYN¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "X3nx5YNQiAr-",
    "outputId": "8f2fc3b7-314f-4df0-b423-84e3fd3b4a68"
   },
   "outputs": [],
   "source": [
    "#Fitting the XGBoost model with best parameters on ADASYN\n",
    "\n",
    "xgbst = XGBClassifier(n_estimators=25,max_depth=5,min_child_weight=3)\n",
    "\n",
    "xgb_ada = xgbst.fit(X_ada,y_ada)\n",
    "\n",
    "#Plotting ROC\n",
    "clf_score(xgb_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzNU4-aviAr_"
   },
   "source": [
    "* AUC is similar in both resampled data scenarios.\n",
    "* With SMOTE XGBoost gives a better Recall but both have a low precision & f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kyhk33uCDaEp"
   },
   "source": [
    "### Choosing the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2W9IxMSDebt"
   },
   "source": [
    "* Base on various scenarios we have applied XGBoost on SMOTE data and got best evaluation metrices. \n",
    "* Instead of aiming for overall accuracy; we consider detecting most of the fraud cases (recall), whilst keeping the cost at which this is achieved under control (precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHtGQN6GDdPg"
   },
   "outputs": [],
   "source": [
    "#Predicting on the test data using the best model\n",
    "y_predicted = xgb_sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVqIcgMSI9vl",
    "outputId": "d9578633-5e9a-4d50-b786-c7f718b41773"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQRCE9tiMJDs"
   },
   "outputs": [],
   "source": [
    "target = 'Class'\n",
    "pca_comp = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n",
    "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n",
    "       'Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "cWcUGl2PMK7U",
    "outputId": "8666a67a-1495-4237-d7f1-c3a6055bbaec"
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({'Feature': pca_comp, 'Feature importance': xgb_sm.feature_importances_})\n",
    "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "plt.figure(figsize = (7,4))\n",
    "plt.title('Features importance',fontsize=14)\n",
    "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIrcPmY_Mi-J"
   },
   "source": [
    "**Insight**\n",
    "* V14 and V4 features are able to explain maximum variance and hence these variable to be target for detect fraud "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vt7MexyM1qu"
   },
   "source": [
    "### Closing Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vNQWZy-MvAf"
   },
   "source": [
    "* Based in provided imbalanced data logistic regression model is built. To work with such imbalance dataset various techniquies like ROS, SMOTE, ADASYN to balance the data are used.\n",
    "\n",
    "* Using the famous logistic regression models like Random Forest, Logistic regression, and boosting techniques (XGboosting) to arrest fraud transactions.\n",
    "\n",
    "* Focus on Recall and AUC as given scenario Accuracy was not a major concern. Also the feature that will important for detecting fraud transactions could be dertermined.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "history_visible": true,
   "machine_shape": "hm",
   "name": "Credit_card_fraud_detection_Starter_code+.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
